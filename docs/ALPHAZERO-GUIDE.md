# AlphaZero è®­ç»ƒæŒ‡å— - 2048 æ¸¸æˆ

## ğŸ¯ å¿«é€Ÿå¼€å§‹

### æµ‹è¯• AlphaZero ç®¡é“ï¼ˆ3 æ¬¡è¿­ä»£ï¼Œ~35 åˆ†é’Ÿï¼‰

```bash
cd /Users/wyp/develop/play2048
uv run python test_alphazero.py
```

**æµ‹è¯•ç»“æœç¤ºä¾‹**ï¼š
```
AlphaZero Training - 2048
Device: mps
Model parameters: 4,875,653
Iterations: 3

Iteration 1/3:
  Self-play: 5 games, 4,856 examples (Ã—8 aug), avg_score=0, win_rate=0%
  Training: Loss=8.71, Policy=8.37, Value=0.67
  Time: 1.3m

Iteration 2/3:
  Self-play: 5 games, 3,608 examples
  Training: Loss=6.28, Policy=6.12, Value=0.31
  Evaluation: 50% win rate vs best
  Time: 17.9m

Iteration 3/3:
  Self-play: 5 games, 3,376 examples
  Training: Loss=5.44, Policy=5.30, Value=0.29
  Time: 16.1m

âœ… Total time: 35.3m
```

### å®Œæ•´è®­ç»ƒï¼ˆ100 æ¬¡è¿­ä»£ï¼Œ~7-10 å¤©ï¼‰

```bash
# åŸºç¡€é…ç½®ï¼ˆæ¨èç”¨äºæµ‹è¯•ï¼‰
uv run python training/train_alphazero.py \
    --iterations 100 \
    --games 100 \
    --mcts-sims 100 \
    --epochs 10 \
    --batch-size 256 \
    --eval-interval 5 \
    --eval-games 50

# å¿«é€Ÿé…ç½®ï¼ˆæ›´å¿«è¿­ä»£ï¼Œä½†æ€§èƒ½ç¨ä½ï¼‰
uv run python training/train_alphazero.py \
    --iterations 100 \
    --games 50 \
    --mcts-sims 50 \
    --epochs 5 \
    --batch-size 128

# é«˜è´¨é‡é…ç½®ï¼ˆæ›´æ…¢ä½†æ€§èƒ½æ›´å¥½ï¼‰
uv run python training/train_alphazero.py \
    --iterations 150 \
    --games 200 \
    --mcts-sims 200 \
    --epochs 15 \
    --batch-size 256 \
    --eval-interval 5
```

### ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ

```bash
uv run python training/train_alphazero.py \
    --resume checkpoints/alphazero/checkpoint_iter50.pth \
    --iterations 100
```

---

## ğŸ“Š è®­ç»ƒå‚æ•°è¯´æ˜

### æ ¸å¿ƒå‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ | å»ºè®®èŒƒå›´ |
|------|-------|------|---------|
| `--iterations` | 100 | è®­ç»ƒè¿­ä»£æ¬¡æ•° | 50-150 |
| `--games` | 100 | æ¯æ¬¡è¿­ä»£çš„è‡ªæˆ‘å¯¹å¼ˆæ¸¸æˆæ•° | 50-200 |
| `--mcts-sims` | 100 | MCTS æ¯æ­¥æ¨¡æ‹Ÿæ¬¡æ•° | 50-400 |
| `--epochs` | 10 | æ¯æ¬¡è¿­ä»£çš„è®­ç»ƒè½®æ•° | 5-20 |
| `--batch-size` | 256 | è®­ç»ƒæ‰¹æ¬¡å¤§å° | 128-512 |

### è¯„ä¼°å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|-------|------|
| `--eval-interval` | 5 | æ¯ N æ¬¡è¿­ä»£è¯„ä¼°ä¸€æ¬¡ |
| `--eval-games` | 50 | è¯„ä¼°æ¸¸æˆæ•°é‡ |

### ç³»ç»Ÿå‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|-------|------|
| `--device` | auto | cpu / cuda / mps / auto |
| `--output-dir` | checkpoints/alphazero | è¾“å‡ºç›®å½• |
| `--save-interval` | 10 | ä¿å­˜æ£€æŸ¥ç‚¹é—´éš” |

---

## ğŸ“ˆ è®­ç»ƒç›‘æ§

### TensorBoard å¯è§†åŒ–

```bash
# å¯åŠ¨ TensorBoard
tensorboard --logdir checkpoints/alphazero/tensorboard

# åœ¨æµè§ˆå™¨è®¿é—®
http://localhost:6006
```

**ç›‘æ§æŒ‡æ ‡**ï¼š
- `SelfPlay/AvgScore` - è‡ªæˆ‘å¯¹å¼ˆå¹³å‡åˆ†æ•°
- `SelfPlay/WinRate` - èƒœç‡ï¼ˆè¾¾åˆ° 2048ï¼‰
- `Train/Loss` - æ€»æŸå¤±
- `Train/PolicyLoss` - ç­–ç•¥æŸå¤±
- `Train/ValueLoss` - ä»·å€¼æŸå¤±
- `Eval/WinRate` - æ–°æ¨¡å‹ vs æœ€ä½³æ¨¡å‹èƒœç‡

### æ£€æŸ¥ç‚¹æ–‡ä»¶

è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šä¿å­˜ï¼š
- `checkpoint_iter10.pth` - æ¯ 10 æ¬¡è¿­ä»£ä¿å­˜
- `final_model.pth` - æœ€ç»ˆæ¨¡å‹
- `tensorboard/` - TensorBoard æ—¥å¿—

---

## ğŸ® ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹ç©æ¸¸æˆ

### æ–¹æ³• 1ï¼šä½¿ç”¨è¯„ä¼°è„šæœ¬

```python
import torch
from models.dual import AlphaZeroNetwork
from training.mcts import MCTS
import numpy as np

# åŠ è½½æ¨¡å‹
device = torch.device('mps')  # æˆ– 'cpu', 'cuda'
model = AlphaZeroNetwork(num_blocks=4, channels=256)
checkpoint = torch.load('checkpoints/alphazero/final_model.pth', weights_only=False)
model.load_state_dict(checkpoint['best_model'])
model.to(device)
model.eval()

# åˆ›å»º MCTS
mcts = MCTS(model, device, num_simulations=200)

# ç©æ¸¸æˆ
from training.selfplay import Game2048

game = Game2048()
while not game.game_over:
    state = game.get_state().numpy()
    policy = mcts.search(state, add_noise=False)
    action = np.argmax(policy)
    game.move(action)

print(f"Final score: {game.score}")
print(f"Max tile: {game.get_max_tile()}")
```

### æ–¹æ³• 2ï¼šæ‰¹é‡æµ‹è¯•

```python
from training.selfplay import self_play_game

# æµ‹è¯• 100 å±€
results = []
for i in range(100):
    _, stats = self_play_game(model, device, mcts_simulations=200, add_noise=False)
    results.append(stats)

# ç»Ÿè®¡
import pandas as pd
df = pd.DataFrame(results)
print(f"Win rate: {df['won'].mean()*100:.1f}%")
print(f"Avg score: {df['score'].mean():.0f}")
print(f"Max tile distribution:\n{df['max_tile'].value_counts().sort_index()}")
```

---

## ğŸ“Š é¢„æœŸè®­ç»ƒè¿›åº¦

### è¿­ä»£ 1-20ï¼ˆæ¢ç´¢é˜¶æ®µï¼‰

**ç›®æ ‡**ï¼šå­¦ä¹ åŸºæœ¬ç­–ç•¥
- èƒœç‡ï¼š0-20%
- å¹³å‡åˆ†æ•°ï¼š500-2000
- æœ€å¤§ç –å—ï¼šä¸»è¦ 128-256
- è®­ç»ƒæŸå¤±ï¼šé€æ¸ä¸‹é™ï¼ˆ8.0 â†’ 5.0ï¼‰

**ç‰¹ç‚¹**ï¼š
- æ¨¡å‹åœ¨æ¢ç´¢å„ç§ç­–ç•¥
- è‡ªæˆ‘å¯¹å¼ˆæ¸¸æˆè´¨é‡è¾ƒä½
- MCTS å¼€å§‹èµ·ä½œç”¨

### è¿­ä»£ 21-50ï¼ˆç¨³å®šé˜¶æ®µï¼‰

**ç›®æ ‡**ï¼šå½¢æˆç¨³å®šç­–ç•¥
- èƒœç‡ï¼š20-50%
- å¹³å‡åˆ†æ•°ï¼š3000-8000
- æœ€å¤§ç –å—ï¼šä¸»è¦ 256-512ï¼Œå¶å°” 1024
- è®­ç»ƒæŸå¤±ï¼šç»§ç»­ä¸‹é™ï¼ˆ5.0 â†’ 3.5ï¼‰

**ç‰¹ç‚¹**ï¼š
- å¼€å§‹å­¦ä¹ è§’è½ä¿æŠ¤
- åˆå¹¶ç­–ç•¥æ›´æœ‰æ•ˆ
- æ¨¡å‹è¯„ä¼°å‡†ç¡®æ€§æé«˜

### è¿­ä»£ 51-100ï¼ˆä¼˜åŒ–é˜¶æ®µï¼‰

**ç›®æ ‡**ï¼šæ¥è¿‘/è¶…è¶Š Expectimax
- èƒœç‡ï¼š50-85%
- å¹³å‡åˆ†æ•°ï¼š10000-18000
- æœ€å¤§ç –å—ï¼šä¸»è¦ 1024-2048ï¼Œ5-10% è¾¾åˆ° 4096
- è®­ç»ƒæŸå¤±ï¼šæ¥è¿‘æ”¶æ•›ï¼ˆ3.5 â†’ 2.5ï¼‰

**ç‰¹ç‚¹**ï¼š
- é•¿æœŸè§„åˆ’èƒ½åŠ›å¢å¼º
- ç­–ç•¥æ¥è¿‘æœ€ä¼˜
- å¼€å§‹è¶…è¶Šä¸“å®¶æ°´å¹³

---

## âš™ï¸ è¶…å‚æ•°è°ƒä¼˜å»ºè®®

### 1. MCTS æ¨¡æ‹Ÿæ¬¡æ•°

**å½±å“**ï¼šæœç´¢è´¨é‡ vs é€Ÿåº¦

```bash
# å¿«é€Ÿè¿­ä»£ï¼ˆå¼€å‘/è°ƒè¯•ï¼‰
--mcts-sims 50

# å¹³è¡¡ï¼ˆæ¨èè®­ç»ƒï¼‰
--mcts-sims 100

# é«˜è´¨é‡ï¼ˆåæœŸ/è¯„ä¼°ï¼‰
--mcts-sims 200-400
```

### 2. è‡ªæˆ‘å¯¹å¼ˆæ¸¸æˆæ•°

**å½±å“**ï¼šæ•°æ®å¤šæ ·æ€§ vs è¿­ä»£é€Ÿåº¦

```bash
# å¿«é€Ÿè¿­ä»£
--games 50

# æ ‡å‡†é…ç½®
--games 100

# æ•°æ®ä¸°å¯Œ
--games 200
```

### 3. è®­ç»ƒè½®æ•°

**å½±å“**ï¼šç½‘ç»œæ‹Ÿåˆ vs è¿‡æ‹Ÿåˆé£é™©

```bash
# è½»é‡è®­ç»ƒï¼ˆé¿å…è¿‡æ‹Ÿåˆï¼‰
--epochs 5

# æ ‡å‡†é…ç½®
--epochs 10

# å……åˆ†è®­ç»ƒï¼ˆå¤§æ•°æ®é›†ï¼‰
--epochs 15-20
```

### 4. æ‰¹æ¬¡å¤§å°

**å½±å“**ï¼šè®­ç»ƒç¨³å®šæ€§ vs å†…å­˜å ç”¨

```bash
# å°å†…å­˜è®¾å¤‡
--batch-size 128

# æ¨èé…ç½®
--batch-size 256

# é«˜å†…å­˜è®¾å¤‡
--batch-size 512
```

---

## ğŸ”§ æ•…éšœæ’é™¤

### é—®é¢˜ 1ï¼šè®­ç»ƒæŸå¤±ä¸ä¸‹é™

**å¯èƒ½åŸå› **ï¼š
- å­¦ä¹ ç‡è¿‡ä½æˆ–è¿‡é«˜
- MCTS æ¨¡æ‹Ÿæ¬¡æ•°å¤ªå°‘
- æ•°æ®è´¨é‡å·®

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# å¢åŠ  MCTS æ¨¡æ‹Ÿ
--mcts-sims 200

# å¢åŠ è‡ªæˆ‘å¯¹å¼ˆæ¸¸æˆ
--games 200

# è°ƒæ•´å­¦ä¹ ç‡ï¼ˆéœ€ä¿®æ”¹ä»£ç ï¼‰
# åœ¨ train_alphazero.py ä¸­è®¾ç½® learning_rate=0.002
```

### é—®é¢˜ 2ï¼šèƒœç‡é•¿æœŸåœæ»

**å¯èƒ½åŸå› **ï¼š
- é™·å…¥å±€éƒ¨æœ€ä¼˜
- æ¢ç´¢ä¸è¶³

**è§£å†³æ–¹æ¡ˆ**ï¼š
- å¢åŠ  Dirichlet å™ªå£°ï¼ˆä»£ç ä¸­å·²åŒ…å«ï¼‰
- æé«˜æ¸©åº¦å‚æ•°æŒç»­æ—¶é—´ï¼ˆä¿®æ”¹ `temperature_moves`ï¼‰
- é‡æ–°åˆå§‹åŒ–æ¨¡å‹ï¼ˆä»é›¶å¼€å§‹ï¼‰

### é—®é¢˜ 3ï¼šæ˜¾å­˜/å†…å­˜ä¸è¶³

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# å‡å°æ‰¹æ¬¡å¤§å°
--batch-size 64

# å‡å°ç½‘ç»œè§„æ¨¡ï¼ˆéœ€ä¿®æ”¹ä»£ç ï¼‰
# åœ¨ train_alphazero.py ä¸­ï¼š
# model = AlphaZeroNetwork(num_blocks=3, channels=128)

# å‡å°‘ MCTS æ¨¡æ‹Ÿ
--mcts-sims 50
```

### é—®é¢˜ 4ï¼šè®­ç»ƒé€Ÿåº¦å¤ªæ…¢

**ä¼˜åŒ–æ–¹æ¡ˆ**ï¼š
```bash
# å‡å°‘è‡ªæˆ‘å¯¹å¼ˆæ¸¸æˆ
--games 50

# å‡å°‘ MCTS æ¨¡æ‹Ÿï¼ˆæ—©æœŸè¿­ä»£ï¼‰
--mcts-sims 50

# å‡å°‘è¯„ä¼°é¢‘ç‡
--eval-interval 10

# ä½¿ç”¨ GPUï¼ˆå¦‚æœå¯ç”¨ï¼‰
--device cuda  # æˆ– mps (Mac)
```

---

## ğŸ“š é«˜çº§æŠ€å·§

### 1. è¯¾ç¨‹å­¦ä¹ ï¼ˆCurriculum Learningï¼‰

é€æ­¥å¢åŠ éš¾åº¦ï¼š

```bash
# é˜¶æ®µ 1ï¼šå¿«é€Ÿæ¢ç´¢ï¼ˆ1-30 æ¬¡è¿­ä»£ï¼‰
--mcts-sims 50 --games 50

# é˜¶æ®µ 2ï¼šç¨³å®šè®­ç»ƒï¼ˆ31-70 æ¬¡è¿­ä»£ï¼‰
--mcts-sims 100 --games 100

# é˜¶æ®µ 3ï¼šç²¾ç»†ä¼˜åŒ–ï¼ˆ71-100 æ¬¡è¿­ä»£ï¼‰
--mcts-sims 200 --games 150
```

### 2. ä»ç›‘ç£å­¦ä¹ åˆå§‹åŒ–

```python
# åŠ è½½é¢„è®­ç»ƒçš„ Transformer æ¨¡å‹æƒé‡
# æ³¨æ„ï¼šéœ€è¦æ‰‹åŠ¨æ˜ å°„å‚æ•°ï¼ˆæ¶æ„ä¸åŒï¼‰
# è¿™å¯ä»¥åŠ é€Ÿå‰ 10-20 æ¬¡è¿­ä»£
```

### 3. é›†æˆå¤šä¸ªæ¨¡å‹

è®­ç»ƒå¤šä¸ªç‹¬ç«‹æ¨¡å‹å¹¶é›†æˆé¢„æµ‹ï¼š

```python
models = [model1, model2, model3]
ensemble_policy = sum([mcts.search(state) for mcts in mcts_list]) / 3
```

---

## ğŸ“ˆ æ€§èƒ½å¯¹æ¯”

### vs ç›‘ç£å­¦ä¹ 

| æŒ‡æ ‡ | ç›‘ç£å­¦ä¹ ï¼ˆ200 epochsï¼‰ | AlphaZeroï¼ˆ100 itersï¼‰ |
|------|---------------------|---------------------|
| è®­ç»ƒæ—¶é—´ | ~50 å°æ—¶ | ~200-300 å°æ—¶ |
| èƒœç‡ | 70%ï¼ˆé¢„æœŸï¼‰ | 85%ï¼ˆç›®æ ‡ï¼‰ |
| å¹³å‡åˆ†æ•° | ~12,000 | ~18,000 |
| æ€§èƒ½ä¸Šé™ | å—é™äºä¸“å®¶ | å¯è¶…è¶Šä¸“å®¶ |
| å®ç°å¤æ‚åº¦ | ä¸­ | é«˜ |

### vs Expectimax

| æŒ‡æ ‡ | Expectimax | AlphaZeroï¼ˆç›®æ ‡ï¼‰ |
|------|-----------|---------------|
| èƒœç‡ | 80% | 85%+ |
| å¹³å‡åˆ†æ•° | ~15,000 | ~18,000 |
| æ¨ç†æ—¶é—´ | 5-10ms | 50-100ms |
| éœ€è¦è®­ç»ƒ | å¦ | æ˜¯ |

---

## ğŸ¯ ä¸‹ä¸€æ­¥è®¡åˆ’

1. **å®Œæˆåˆæ­¥è®­ç»ƒ**ï¼ˆ20-30 æ¬¡è¿­ä»£ï¼‰
   - éªŒè¯è®­ç»ƒæµç¨‹
   - è§‚å¯ŸæŸå¤±æ›²çº¿
   - è°ƒæ•´è¶…å‚æ•°

2. **ä¸­æœŸè¯„ä¼°**ï¼ˆ50 æ¬¡è¿­ä»£ï¼‰
   - vs Expectimax å¯¹æˆ˜æµ‹è¯•
   - åˆ†æç­–ç•¥å·®å¼‚
   - ä¼˜åŒ– MCTS å‚æ•°

3. **å®Œæ•´è®­ç»ƒ**ï¼ˆ100 æ¬¡è¿­ä»£ï¼‰
   - è¾¾åˆ°ç›®æ ‡æ€§èƒ½
   - ä¿å­˜æœ€ä½³æ¨¡å‹
   - æ’°å†™ç»“æœæŠ¥å‘Š

4. **æ¨¡å‹å‹ç¼©**ï¼ˆå¯é€‰ï¼‰
   - çŸ¥è¯†è’¸é¦åˆ°å°æ¨¡å‹
   - é‡åŒ–åŠ é€Ÿæ¨ç†
   - éƒ¨ç½²åˆ° Web æµè§ˆå™¨

---

## ğŸ“ å¼•ç”¨

å¦‚æœä½¿ç”¨æ­¤å®ç°ï¼Œè¯·å¼•ç”¨ï¼š

```bibtex
@misc{play2048_alphazero,
  title={AlphaZero for 2048 Game},
  author={Your Name},
  year={2026},
  url={https://github.com/inforix/play2048}
}
```

**å‚è€ƒè®ºæ–‡**ï¼š
- Silver et al. (2017) - AlphaGo Zero
- Silver et al. (2018) - AlphaZero
- Browne et al. (2012) - MCTS Survey

---

**æœ€åæ›´æ–°**ï¼š2026-01-08  
**ç‰ˆæœ¬**ï¼š1.0  
**çŠ¶æ€**ï¼šâœ… å®Œæ•´å®ç°å¹¶æµ‹è¯•é€šè¿‡
